"use strict";(self.webpackChunkcurvine_doc=self.webpackChunkcurvine_doc||[]).push([[7151],{8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>s});var i=r(6540);const t={},o=i.createContext(t);function a(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(o.Provider,{value:n},e.children)}},9107:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"User-Manuals/opt","title":"Performance Tuning","description":"This chapter introduces how to optimize Curvine\'s performance.","source":"@site/docs/3-User-Manuals/05-opt.md","sourceDirName":"3-User-Manuals","slug":"/User-Manuals/opt","permalink":"/docs/User-Manuals/opt","draft":false,"unlisted":false,"editUrl":"https://github.com/curvineio/curvine-doc/edit/master/docs/3-User-Manuals/05-opt.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Command Line Tools","permalink":"/docs/User-Manuals/cli"},"next":{"title":"Configuration Reference","permalink":"/docs/User-Manuals/conf"}}');var t=r(4848),o=r(8453);const a={},s="Performance Tuning",c={},l=[{value:"Server-Side Performance Tuning",id:"server-side-performance-tuning",level:2},{value:"Client-Side Performance Tuning",id:"client-side-performance-tuning",level:2},{value:"Sequential Read/Write Scenarios",id:"sequential-readwrite-scenarios",level:3},{value:"High Concurrency Read/Write Scenarios",id:"high-concurrency-readwrite-scenarios",level:3},{value:"Large File Sequential Read",id:"large-file-sequential-read",level:3},{value:"Random Read",id:"random-read",level:3},{value:"FUSE Performance Optimization",id:"fuse-performance-optimization",level:2},{value:"Memory Control",id:"memory-control",level:3},{value:"Metadata Performance Optimization",id:"metadata-performance-optimization",level:3},{value:"FUSE2 Optimization Solution",id:"fuse2-optimization-solution",level:3}];function d(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"performance-tuning",children:"Performance Tuning"})}),"\n",(0,t.jsx)(n.p,{children:"This chapter introduces how to optimize Curvine's performance."}),"\n",(0,t.jsx)(n.h2,{id:"server-side-performance-tuning",children:"Server-Side Performance Tuning"}),"\n",(0,t.jsx)(n.p,{children:"The default configuration is suitable for most scenarios. In high-load environments, you can adjust the following parameters:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Thread count tuning"}),": Adjust the number of worker threads based on CPU cores and business load"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Kernel parameter optimization"}),": Adjust network buffers, resource limits, and other parameters"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Curvine configuration adjustment example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"# io_threads = CPU cores, worker_threads = CPU cores * 2\n[master]\nio_threads = 32\nworker_threads = 64\n\n[worker]\nio_threads = 32\nworker_threads = 64\n"})}),"\n",(0,t.jsx)(n.p,{children:"Kernel parameter adjustment example (configuration examples show which parameters affect performance, for reference only, adjust according to actual needs):"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Adjust maximum file open count\nulimit -n 128000\n\n# Adjust network parameters\necho "\nnet.ipv4.tcp_rmem=8192    128000  33554432\nnet.ipv4.tcp_wmem=8192    128000  33554432\nnet.core.rmem_max=67108864\nnet.core.wmem_max=67108864\nnet.ipv4.tcp_mem=94500000     915000000       927000000\n" > /etc/sysctl.d/99-curvine-sysctl.conf\n'})}),"\n",(0,t.jsx)(n.h2,{id:"client-side-performance-tuning",children:"Client-Side Performance Tuning"}),"\n",(0,t.jsx)(n.h3,{id:"sequential-readwrite-scenarios",children:"Sequential Read/Write Scenarios"}),"\n",(0,t.jsx)(n.p,{children:"Sequential read/write scenarios can achieve optimal performance using default configurations."}),"\n",(0,t.jsx)(n.h3,{id:"high-concurrency-readwrite-scenarios",children:"High Concurrency Read/Write Scenarios"}),"\n",(0,t.jsx)(n.p,{children:"When clients need to handle a large number of file I/O operations simultaneously:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Set ",(0,t.jsx)(n.code,{children:"read_chunk_num=1"})," and ",(0,t.jsx)(n.code,{children:"write_chunk_num=1"})," to reduce memory usage"]}),"\n",(0,t.jsx)(n.li,{children:"Suitable for scenarios with concurrent file count > 1000"}),"\n",(0,t.jsx)(n.li,{children:"Single file throughput will decrease, but overall throughput remains unchanged, memory usage will decrease by 90%"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Configuration example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"[client]\nread_chunk_num = 1\nwrite_chunk_num = 1\n"})}),"\n",(0,t.jsx)(n.h3,{id:"large-file-sequential-read",children:"Large File Sequential Read"}),"\n",(0,t.jsx)(n.p,{children:"For sequential reading of single large files (>100GB):"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Recommended parallelism = 4-16"}),"\n",(0,t.jsx)(n.li,{children:"Performance can improve 3-5 times, reaching 2-3GB/s"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Configuration example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"# Set read parallelism\n[client]\nread_parallel = 8\n"})}),"\n",(0,t.jsx)(n.h3,{id:"random-read",children:"Random Read"}),"\n",(0,t.jsx)(n.p,{children:"For completely random reads, it's recommended to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set buffer to 1 to avoid read amplification"}),"\n",(0,t.jsx)(n.li,{children:"Make chunk_size close to average I/O size (e.g., 4KB/256KB)"}),"\n",(0,t.jsx)(n.li,{children:"For large files, set block_size \u2265 1GB to reduce connection count"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Configuration example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:'[client]\nread_chunk_num = 1\n# Adjust according to actual I/O patterns\nread_chunk_size = "256KB"\n'})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsx)(n.p,{children:"In completely random read scenarios, the client will cache connections with workers to reduce connection establishment overhead. However, if a file is very large, it will have many blocks, leading to too many connections. It's recommended to set block_size to 1GB or above when writing such large files to reduce connection count."})}),"\n",(0,t.jsx)(n.h2,{id:"fuse-performance-optimization",children:"FUSE Performance Optimization"}),"\n",(0,t.jsx)(n.p,{children:"Curvine FUSE currently supports FUSE2 and FUSE3. FUSE2's performance is approximately only 50% of FUSE3, so it's recommended to use FUSE3 in production environments."}),"\n",(0,t.jsx)(n.h3,{id:"memory-control",children:"Memory Control"}),"\n",(0,t.jsx)(n.p,{children:"If FUSE is deployed on memory-constrained machines, you can set queue sizes to reduce memory usage:"}),"\n",(0,t.jsx)(n.p,{children:"Configuration example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"[fuse]\n# Set FUSE request queue size\nfuse_channel_size = 1024\n\n# Set read/write data queue buffer size\nstream_channel_size = 16\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"warning",children:(0,t.jsx)(n.p,{children:"Curvine FUSE currently does not support page cache."})}),"\n",(0,t.jsx)(n.h3,{id:"metadata-performance-optimization",children:"Metadata Performance Optimization"}),"\n",(0,t.jsxs)(n.p,{children:["In traditional libfuse implementations, metadata may be blocked by data read/write requests, causing request delays. Users are usually advised to set ",(0,t.jsx)(n.code,{children:"attr_timeout"})," and ",(0,t.jsx)(n.code,{children:"entry_timeout"})," to let the kernel cache metadata and improve performance."]}),"\n",(0,t.jsxs)(n.p,{children:["However, in Curvine's FUSE implementation, FUSE request processing is completely asynchronous, so there's no need to set ",(0,t.jsx)(n.code,{children:"attr_timeout"})," and ",(0,t.jsx)(n.code,{children:"entry_timeout"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Of course, if needed, you can also increase cache time. Configuration example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"# Set metadata expiration time to 60s, default is 1s\n[fuse]\nentry_timeout = 60\nattr_timeout = 60\n"})}),"\n",(0,t.jsx)(n.p,{children:"If you want modifications to be visible in real-time, you can set expiration time to 0, which won't affect FUSE performance:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"[fuse]\nentry_timeout = 0\nattr_timeout = 0\n"})}),"\n",(0,t.jsx)(n.h3,{id:"fuse2-optimization-solution",children:"FUSE2 Optimization Solution"}),"\n",(0,t.jsx)(n.p,{children:"If your environment can only use FUSE2 and you want to improve performance, you can use multiple mount points as a solution. In actual testing, 4-8 mount points can achieve about 80% of FUSE3's performance."}),"\n",(0,t.jsx)(n.p,{children:"Configuration example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-toml",children:"[fuse]\nmnt_number = 4\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsx)(n.p,{children:"Multiple mount points will mount multiple directories in the operating system. Programs need to use random or round-robin methods to select mount points to distribute the load."})})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);